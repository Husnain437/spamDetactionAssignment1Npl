{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2C_N3CZUGJO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "from nltk.classify.util import accuracy\n",
        "\n",
        "dataset = \"/content/emails.csv\"\n",
        "emailDataFrame = pd.read_csv(dataset)\n",
        "\n",
        "#droping column email number because its not needed\n",
        "emailDataFrame = emailDataFrame.drop(columns=['Email No.'])\n",
        "\n",
        "#droping column prediction in the input and assigning column prediction to output\n",
        "X = emailDataFrame.drop(columns=['Prediction'])\n",
        "y = emailDataFrame['Prediction']\n",
        "\n",
        "#spliting data into trainSet and testSet\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "#converting data formate into nltk supported formate\n",
        "def convertFormate(X, y):\n",
        "    dataNltk = []\n",
        "    for i in range(len(X)):\n",
        "        feature_dict = {str(word): X.iloc[i][word] for word in X.columns}\n",
        "        dataNltk.append((feature_dict, y.iloc[i]))\n",
        "    return dataNltk\n",
        "\n",
        "dataTrain = convertFormate(X_train, y_train)\n",
        "dataTest = convertFormate(X_test, y_test)\n",
        "\n",
        "#using Naive base classifier for training\n",
        "classifier = NaiveBayesClassifier.train(dataTrain)\n",
        "\n",
        "#checking accuracing and printing it\n",
        "accuracy_score = accuracy(classifier, dataTest)\n",
        "print(f\"Accuracy: {accuracy_score:.2f}\")\n",
        "\n",
        "#pridicting label\n",
        "predic = [classifier.classify(sample[0]) for sample in dataTest]\n",
        "realData = y_test.values\n",
        "\n",
        "#calculating confusion matrix\n",
        "conf_matrix = confusion_matrix(realData, predic)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", classification_report(realData, predic))\n",
        "\n",
        "#calculating f1 score and printing\n",
        "f1 = f1_score(realData, predic)\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n"
      ]
    }
  ]
}